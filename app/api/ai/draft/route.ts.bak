import { createServerClient } from '@supabase/ssr'
import { cookies } from 'next/headers'
import { openai } from '@ai-sdk/openai'
import { streamText } from 'ai'

import { getAuthenticatedSession } from '@/lib/auth-helper'

export async function POST(request: Request) {
  // Support Bearer token authentication
  const auth = await getAuthenticatedSession(request)
  if (!auth) {
    return new Response('Unauthorized', { status: 401 })
  }

  const cookieStore = await cookies()
  const supabase = createServerClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
    {
      cookies: {
        getAll() {
          return cookieStore.getAll()
        },
        setAll(cookiesToSet) {
          try {
            cookiesToSet.forEach(({ name, value, options }) =>
              cookieStore.set(name, value, options)
            )
          } catch {
            // Ignore
          }
        },
      },
    }
  )

  // Get user's account_id
  const { data: user } = await supabase
    .from('users')
    .select('account_id')
    .eq('id', auth.user.id)
    .single()

  const { conversationId } = await request.json()

  // 2. Fetch History
  const { data: messages } = await supabase
    .from('messages')
    .select('direction, body_text, sender_type')
    .eq('conversation_id', conversationId)
    .order('created_at', { ascending: true })
    .limit(20) // Last 20 messages

  if (!messages || messages.length === 0) {
    return new Response('No messages found', { status: 404 })
  }

  // 3. Format History for AI
  const history = messages.map(m => 
    `${m.direction === 'inbound' ? 'Customer' : 'You'}: ${m.body_text}`
  ).join('\n')

  // 3.5. Get RAG context from knowledge docs (if available)
  let ragContext = ''
  if (user?.account_id && process.env.NEXT_PUBLIC_SUPABASE_URL) {
    try {
      const lastCustomerMessage = messages.filter(m => m.direction === 'inbound').pop()
      if (lastCustomerMessage) {
        const ragUrl = `${process.env.NEXT_PUBLIC_SUPABASE_URL}/functions/v1/rag-search`
        const ragResponse = await fetch(ragUrl, {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${process.env.SUPABASE_SERVICE_ROLE_KEY}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            accountId: user.account_id,
            query: lastCustomerMessage.body_text,
            limit: 3,
          }),
        })
        
        if (ragResponse.ok) {
          const ragData = await ragResponse.json()
          if (ragData.context) {
            ragContext = `\n\nRelevant Knowledge:\n${ragData.context}\n`
          }
        }
      }
    } catch (error) {
      console.error('RAG search error:', error)
      // Continue without RAG context
    }
  }

  // 4. Get persona config from account
  let personaConfig: any = {}
  if (user?.account_id) {
    const { data: account } = await supabase
      .from('accounts')
      .select('persona_config')
      .eq('id', user.account_id)
      .single()
    
    personaConfig = account?.persona_config || {}
  }

  // 5. Use LLM Router Edge Function if available, otherwise fallback to direct OpenAI
  const useLLMRouter = process.env.USE_LLM_ROUTER !== 'false'
  
  if (useLLMRouter && process.env.NEXT_PUBLIC_SUPABASE_URL) {
    try {
      const routerUrl = `${process.env.NEXT_PUBLIC_SUPABASE_URL}/functions/v1/llm-router`
      const routerResponse = await fetch(routerUrl, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.SUPABASE_SERVICE_ROLE_KEY}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          accountId: user?.account_id,
          useCase: 'draft',
          prompt: `Conversation History:\n${history}${ragContext}\n\nDraft a reply:`,
          systemPrompt: personaConfig.systemPrompt || `You are Carl, an assistant for CRM-AI PRO. 
    Service Area: Indianapolis, Carmel, Fishers.
    Pricing: $89 Diagnostic Fee (waived if work is done).
    Urgency: If water is actively leaking, tell them to shut off the main valve immediately.
    
    Your goal is to be helpful, brief, and ask for the address if missing.
    Draft a response to the customer based on the conversation history.
    Do not include "Subject:" lines. Just the body.`,
          maxTokens: 500,
          temperature: 0.7,
        }),
      })

      if (routerResponse.ok) {
        const routerData = await routerResponse.json()
        // Return as streaming response
        return new Response(
          new ReadableStream({
            start(controller) {
              controller.enqueue(new TextEncoder().encode(routerData.text))
              controller.close()
            }
          }),
          { headers: { 'Content-Type': 'text/plain; charset=utf-8' } }
        )
      }
    } catch (error) {
      console.error('LLM Router error, falling back to direct:', error)
      // Fall through to direct OpenAI
    }
  }

  // 6. Use OpenAI with tool calling for advanced interactions
  const tools = {
    create_job: {
      description: 'Create a new job if the customer needs service',
      parameters: {
        type: 'object',
        properties: {
          contactId: { type: 'string' },
          description: { type: 'string' },
          scheduledStart: { type: 'string' },
        },
        required: ['contactId', 'description'],
      },
    },
    search_contacts: {
      description: 'Search for a contact by name, email, or phone',
      parameters: {
        type: 'object',
        properties: {
          search: { type: 'string' },
        },
        required: ['search'],
      },
    },
  }

  const result = streamText({
    model: openai('gpt-4o-mini'),
    system: personaConfig.systemPrompt || `You are Carl, an assistant for CRM-AI PRO. 
    Service Area: Indianapolis, Carmel, Fishers.
    Pricing: $89 Diagnostic Fee (waived if work is done).
    Urgency: If water is actively leaking, tell them to shut off the main valve immediately.
    
    Your goal is to be helpful, brief, and ask for the address if missing.
    Draft a response to the customer based on the conversation history.
    You can use tools to create jobs or search contacts if needed.
    Do not include "Subject:" lines. Just the body.`,
    prompt: `Conversation History:\n${history}${ragContext}\n\nDraft a reply:`,
    tools,
    maxSteps: 3, // Allow tool calling but limit steps
  })

  return result.toTextStreamResponse()
}

